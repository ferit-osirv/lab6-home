{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb2ObAKq3-en"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ferit-osirv/lab6-home/blob/main/lab6_home.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AH72BIFyfbY"
      },
      "source": [
        "## Lab 6: Feature Detection and Image Retrieval\n",
        "\n",
        "In this lab, you will develop an image retrieval algorithm. Image retrieval involves finding images within a large dataset that match a given query image. For example, if the query image features the Eiffel Tower, the image retrieval algorithm should identify and retrieve all images containing the Eiffel Tower.\n",
        "\n",
        "**Note:** Depending on your group ID, you will later be assigned a specific landmark to track.\n",
        "\n",
        "## Resources\n",
        "\n",
        "Most of the resources required for this assignment can be found in this guide:\n",
        "\n",
        "[OpenCV Documentation: Feature Detection and Description](https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html)\n",
        "\n",
        "Please read through all sections, paying particular attention to the section relevant to your assigned method and the last two sections. The last two sections will be essential for implementing this assignment.\n",
        "\n",
        "## Image Retrieval Algorithm\n",
        "\n",
        "The algorithm will operate as follows:\n",
        "\n",
        "**Step 1:** Perform feature matching between each query image and every search image using a feature detection algorithm such as FAST, SIFT, etc.\n",
        "\n",
        "**Step 2:** If there are more than a certain number of matches (e.g., 10) between a query and a search image, we can conclude that the search image contains the landmark. This result is stored as either true or false.\n",
        "\n",
        "**Step 3:** Calculate the true positive and false positive rates to evaluate the algorithm's performance.\n",
        "\n",
        "**Algorithm in Pseudocode**\n",
        "\n",
        "Input: A list of query images featuring a specific landmark, a list of images for searching, some of which contain the landmark and some that do not, and a threshold value (e.g., 10) for the number of matches required to confirm the presence of the landmark in an image.\n",
        "\n",
        "```python\n",
        "image_contains_landmark = []\n",
        "for each image with index i:\n",
        "  image_contains_landmark[i] = false\n",
        "\n",
        "for each query image:\n",
        "  for each image with index i:\n",
        "    matches = match_features(query, image)\n",
        "    if matches count > threshold:\n",
        "      image_contains_landmark[i] = true\n",
        "```\n",
        "\n",
        "**Feature Matching**\n",
        "\n",
        "The feature matching process should proceed in several steps (as explained in the \"Feature Matching\" section referenced above):\n",
        "\n",
        "**Step 1:** Conduct feature detection on the query image using **ORB**.\n",
        "\n",
        "**Step 2:** Perform feature detection on the search image using **ORB**.\n",
        "\n",
        "**Step 3:** Use **FLANN (Fast Approximate Nearest Neighbor Search Library)** with Lowe's ratio test to match the features of the query and search image.\n",
        "\n",
        "**Step 4:** Implement **Lowe's ratio test** to retain only features below a certain distance threshold.\n",
        "\n",
        "**Step 5:** Return the matches that are above the distance threshold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03fEpaSOw446"
      },
      "source": [
        "## Dataset Downloading Code\n",
        "\n",
        "The code block below downloads the following dataset:\n",
        "\n",
        "https://github.com/filipradenovic/revisitop (rparis6k)\n",
        "published in: Radenović, F., Iscen, A., Tolias, G., Avrithis, Y., & Chum, O. (2018). Revisiting Oxford and Paris: Large-Scale Image Retrieval Benchmarking. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 5706-5715.\n",
        "\n",
        "The dataset contains thousands of images of various landmarks in Paris, France. It also contains query images for each landmark, and labels of which landmark is on each image.\n",
        "\n",
        "The code block also defines helper functions which will be explained later in the notebook.\n",
        "\n",
        "**⚠️ Click the ▶️ button to run the cell below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQBqnEnbfBfY",
        "outputId": "37cdbeef-c2c0-4c83-c69d-d240ab45d6c4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import os.path as p\n",
        "\n",
        "# clone git repository\n",
        "if not os.path.exists('images'):\n",
        "    !git clone https://github.com/ferit-osirv/lab6-home.git\n",
        "    shutil.move('lab6-home/images', 'images')\n",
        "    shutil.rmtree('lab6-home')\n",
        "\n",
        "def get_query_img(landmark):\n",
        "  fname = p.join('images', 'query', landmark + '.jpg')\n",
        "  img = cv.imread(fname)\n",
        "  img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "def get_imgs(landmark):\n",
        "  imgs = []\n",
        "  folder = p.join('images', landmark)\n",
        "  for fname in os.listdir(folder):\n",
        "    if fname.split('.')[-1] != 'jpg':\n",
        "      continue\n",
        "    img = cv.imread(p.join(folder, fname))\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "    imgs.append(img)\n",
        "  return imgs\n",
        "\n",
        "def get_img_fnames(landmark):\n",
        "  fnames = []\n",
        "  folder = p.join('images', landmark)\n",
        "  for fname in os.listdir(folder):\n",
        "    if fname.split('.')[-1] != 'jpg':\n",
        "      continue\n",
        "    fnames.append(p.join(folder, fname))\n",
        "  return fnames\n",
        "\n",
        "landmarks = ['eiffel', 'louvre', 'defense', 'moulinrouge', 'invalides']\n",
        "\n",
        "all_img_fnames = []\n",
        "for landmark in landmarks:\n",
        "  all_img_fnames += get_img_fnames(landmark)\n",
        "\n",
        "num_imgs = len(all_img_fnames)\n",
        "\n",
        "def get_img_fname(i):\n",
        "  return all_img_fnames[i]\n",
        "\n",
        "def get_img(i):\n",
        "  img = cv.imread(get_img_fname(i))\n",
        "  img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsQWTkaa0_l5"
      },
      "source": [
        "## Groups\n",
        "\n",
        "In the notice of this lab, you received a group number.\n",
        "\n",
        "**⚠️ Enter the assignment group id below and run the block get your landmark and method.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "jCGJ6u-juLV9",
        "outputId": "809a8772-b9b1-4635-9c71-dbe9344dc944"
      },
      "outputs": [],
      "source": [
        "# @title  { run: \"auto\", vertical-output: true }\n",
        "group_id = 0 # @param {type:\"integer\"}\n",
        "assert len(str(group_id)) == 1, \"Incorrect group\"\n",
        "\n",
        "landmarks = ['pantheon', 'louvre', 'notredame', 'triomphe', 'eiffel']\n",
        "methods = ['SIFT', 'ORB', 'FAST']\n",
        "\n",
        "assert (group_id - 1) >= 0 and (group_id - 1) < len(landmarks), \"Incorrect group\"\n",
        "\n",
        "landmark = landmarks[group_id - 1]\n",
        "print(\"Your landmark:\", landmark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g27OTOfoOM6"
      },
      "source": [
        "## Documentation\n",
        "\n",
        "**Available predefined functions in this notebook**:\n",
        "\n",
        "\n",
        " - `get_query_imgs(landmark)` - load a list of query images\n",
        "   - `landmark` can be `'pantheon', 'louvre', 'notredame', 'triomphe', 'eiffel'`.\n",
        " - `get_img(i)` - load the `i`th image from the dataset\n",
        " - `get_img_fname(i)` - returns the file name of the image\n",
        " - `num_imgs` - the total number of images in the dataset\n",
        " - `get_imgs(landmark)` - get all images of a certain landmark, useful for evaluation\n",
        " - `get_img_fnames(landmark)` - get all image filenames of a certain landmark, useful for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1376
        },
        "id": "hp5C9uf4zzFB",
        "outputId": "1f54c6dc-7757-485c-a162-6701d5830f2d"
      },
      "outputs": [],
      "source": [
        "# Some example code\n",
        "\n",
        "query_img = get_query_img('eiffel')\n",
        "plt.imshow(query_img)\n",
        "plt.title('Example Query');\n",
        "plt.show()\n",
        "\n",
        "example_img = get_img(40)\n",
        "plt.imshow(example_img)\n",
        "plt.title('Example Image');\n",
        "plt.show()\n",
        "\n",
        "example_eiffel_img = get_imgs('eiffel')[5]\n",
        "plt.imshow(example_eiffel_img)\n",
        "plt.title('Example Image of the Eiffel Tower');\n",
        "plt.show()\n",
        "\n",
        "print('Image 40', get_img_fname(40))\n",
        "print('All Eiffel images', get_img_fnames('eiffel'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nRWczz3yU1P"
      },
      "source": [
        "## Assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u_DMXpmksLv"
      },
      "outputs": [],
      "source": [
        "print(landmark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gGMJXM3vxFX"
      },
      "source": [
        "## Initial Algorithm Development\n",
        "\n",
        "For algorithm development, it is faster to only go through known images of that landmark.\n",
        "\n",
        "Later in the notebook, you will perform the search across all images.\n",
        "\n",
        "Before you start development here, it might be a good idea to first try implementing feature matching for just one query and one search image. You can then convert that code to a for loop to go through multiple images as in the block below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement ORB by detecting keypoints and computing descriptors\n",
        "#      for the query and the search image. Match the descriptors\n",
        "#      using a FLANN-based matcher. Use cv.drawMatchesKnn to\n",
        "#      visualize the matches. You can use the provided materials as a reference.\n",
        "\n",
        "query_img = get_query_img(landmark)\n",
        "search_img = get_imgs(landmark)[0]\n",
        "\n",
        "# Note: Detect the features on grayscale images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we can compute the features across all images and store them in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For this initial phase, we will only go through known landmarks.\n",
        "# Later in this notebook, we will go through every image in the dataset.\n",
        "known_landmark_fnames = get_img_fnames(landmark)\n",
        "known_landmark_imgs = get_imgs(landmark)\n",
        "query_img = get_query_img(landmark)\n",
        "\n",
        "query_features = # TODO: Detect features on the query image\n",
        "detected_features = []\n",
        "for img in known_landmark_imgs:\n",
        "  # TODO\n",
        "  # detect keypoints and descriptors\n",
        "  # keypoints, descriptors = ...\n",
        "  # detected_features.append((keypoints, descriptors))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have a feature for all image, we can go through them and try to match them using FLANN. Take a look at the introduction text and the references to understand how to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "matched_fnames = []\n",
        "\n",
        "for image_fname, features in zip(known_landmark_fnames, detected_features):\n",
        "  keypoints, descriptors = features\n",
        "  # TODO: Perform matching between the query image and the current image using FLANN and ratio test.\n",
        "  # Note: You might get an error in the line ̨ `kp1, kp2 in matches` if there are no matches.\n",
        "  # Instead, use `match in matches` and check if `len(matches) < 2`. If so, skip the image.\n",
        "  # Note: Feel free to change the matches threshold to get better results (capture more matches).\n",
        "\n",
        "  is_match = False\n",
        "  if is_match:\n",
        "    matched_fnames.append(image_fname)\n",
        "\n",
        "print('Matched images:', len(matched_fnames))\n",
        "print('Known matches:', len(known_landmark_fnames))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you have implemented the image matchign process for a limited subset of the data. Next, you will implement the same algorithm for all images in the dataset.\n",
        "\n",
        "## Run the Algorithm on All Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmAYU3C_k7zB"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement the specified feature detection method for all images.\n",
        "\n",
        "query_image = # TODO\n",
        "query_features = # TODO\n",
        "img_features = []\n",
        "\n",
        "for i in range(num_imgs):\n",
        "  img = get_img(i)\n",
        "  img_fname = get_img_fname(i)\n",
        "  # TODO\n",
        "  # detect keypoints and descriptors as earlier\n",
        "\n",
        "matched_fnames = []\n",
        "# TODO: Perform matching between the query image and all images using FLANN\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTzy0Ai7wkul"
      },
      "source": [
        "Now that we have the results on the whole dataset, we can evaluate the performance of the algorithm.\n",
        "\n",
        "## Evaluation\n",
        "\n",
        "For evaluation, you will calculate values of the confusion matrix.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Confusion_matrix\n",
        "\n",
        "True positives: Landmark is detected by your algorithm and is really a landmark; i.e. landmark is in both `matched_fnames` and `known_landmark_fnames`.\n",
        "\n",
        "False positives: Landmark is matched by your algorithm but in reality the image does not contain the landmark; i.e. landmark is in `matched_fnames` but not in `known_landmark_fnames`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCjAb_-trT-o"
      },
      "outputs": [],
      "source": [
        "# Calculate number of true positives and false positives\n",
        "#\n",
        "# True positives: Landmark is in both matched_fnames and known_landmark_fnames\n",
        "# False positives: Landmark is in matched_fnames but not in known_landmark_fnames\n",
        "\n",
        "def get_confusion_matrix(matched_fnames, known_landmark_fnames, num_imgs):\n",
        "  '''\n",
        "  matched_fnames: Your retrieval results from all images.\n",
        "  known_landmark_fnames: Known GT landmark names.\n",
        "  '''\n",
        "  # TODO: Calculate the values\n",
        "  tp = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  tn = num_imgs - (tp + fp + fn)\n",
        "  return (tp, fp, tn, fn)\n",
        "\n",
        "# Test if confusion matrix works correctly\n",
        "matched_fnames_test = ['eiffel_0, eiffel_1, eiffel_2, louvre_0']\n",
        "known_landmark_fnames_test = ['eiffel_0', 'eiffel_1', 'eiffel_2', 'eiffel_3']\n",
        "# (tp, fp, tn, fn)\n",
        "test_cm = (3, 1, num_imgs - (3 + 1 + 1), 1)\n",
        "assert test_cm == get_confusion_matrix(matched_fnames_test, known_landmark_fnames_test, num_imgs),\\\n",
        "  \"Your function is not implemented correctly.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQRsWN7BsFnU"
      },
      "outputs": [],
      "source": [
        "# Print the confusion matrix values\n",
        "\n",
        "tp, fp, tn, fn = get_confusion_matrix(matched_fnames, known_landmark_fnames, num_imgs)\n",
        "print(f'{tp}\\t{fp}')\n",
        "print(f'{fn}\\t{tn}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMhH0BKxxv9_"
      },
      "source": [
        "**Final step:** Try to modify your matches threshold to increase the number of true positives."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPbnmRhqw2xVDi0SSYuqloW",
      "collapsed_sections": [
        "03fEpaSOw446"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
